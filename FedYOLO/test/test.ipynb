{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################\n",
      "# CLIENT RESULTS #\n",
      "##################\n",
      "\n",
      "/home/localssk23/UltraFlwr\n",
      "Ultralytics 8.3.48 ðŸš€ Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/localssk23/backup/soumya/env/fedlytics/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/partitions/client_0/valid/labels.cache... 6 images, 6 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         12         12    0.00177        0.3     0.0818     0.0412\n",
      "Speed: 0.9ms preprocess, 44.1ms inference, 0.0ms loss, 6.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
      "Ultralytics 8.3.48 ðŸš€ Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/valid/labels... 25 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 2473.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/localssk23/UltraFlwr/datasets/baseline/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25         48    0.00394      0.359     0.0596     0.0317\n",
      "Speed: 0.7ms preprocess, 45.5ms inference, 0.0ms loss, 8.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
      "/home/localssk23/UltraFlwr\n",
      "Ultralytics 8.3.48 ðŸš€ Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/partitions/client_1/valid/labels.cache... 7 images, 6 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         13         13    0.00144      0.273     0.0556     0.0387\n",
      "Speed: 0.9ms preprocess, 47.8ms inference, 0.0ms loss, 6.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
      "Ultralytics 8.3.48 ðŸš€ Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/valid/labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25         48    0.00348      0.359     0.0756     0.0457\n",
      "Speed: 0.7ms preprocess, 45.2ms inference, 0.0ms loss, 10.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n",
      "\n",
      "\n",
      "##############################\n",
      "# FINAL CONSOLIDATED METRICS #\n",
      "##############################\n",
      "  Class  mAP@0.5:0.95_local_0  mAP@0.5:0.95_global_0  mAP@0.5:0.95_local_1  mAP@0.5:0.95_global_1\n",
      "cheetah              0.082355               0.063342              0.077394               0.091493\n",
      "  human              0.000000               0.000000              0.000000               0.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from extract_final_save_from_client import extract_results_path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from FedYOLO.config import HOME, SPLITS_CONFIG, SERVER_CONFIG\n",
    "\n",
    "DATASET_NAME = SPLITS_CONFIG['dataset_name']\n",
    "NUM_ROUNDS = SERVER_CONFIG['rounds']\n",
    "\n",
    "#! HUGE DIFFERENCES BETWEEN SYSTEMS REGARDING FILES PATHS AND LOGGING. NEED TO IN-DEPTH TEST THIS.\n",
    "\n",
    "#####################\n",
    "# CLIENT EVALUATION #\n",
    "#####################\n",
    "\n",
    "def get_client_metrics(client_number, dataset_name, home_path):\n",
    "    # Extract paths\n",
    "    print(home_path)\n",
    "    client_model_weights_path = extract_results_path(f\"{home_path}/logs/client_{client_number}_log_{dataset_name}.txt\")\n",
    "    weights = f\"{home_path}/{client_model_weights_path}/weights/best.pt\"\n",
    "    \n",
    "    # Load and validate local model\n",
    "    client_model = YOLO(weights)\n",
    "    client_metrics = client_model.val(data=f'{home_path}/datasets/{dataset_name}/partitions/client_{client_number}/data.yaml', verbose=False)\n",
    "    \n",
    "    # Create local model metrics table\n",
    "    client_table = pd.DataFrame({\n",
    "        'Class': list(client_metrics.names.values()),\n",
    "        'mAP@0.5:0.95': client_metrics.box.maps.tolist()\n",
    "    })\n",
    "    \n",
    "    # Extract global model weights\n",
    "    client_global_model_weights_path = extract_results_path(f\"{home_path}/logs/client_{client_number}_log_{dataset_name}.txt\")\n",
    "    global_weights = f\"{home_path}/{client_global_model_weights_path}/weights/best.pt\"\n",
    "    \n",
    "    # Load and validate global model\n",
    "    client_global_model = YOLO(global_weights)\n",
    "    client_global_metrics = client_global_model.val(data=f'{home_path}/datasets/{dataset_name}/data.yaml', verbose=False)\n",
    "    \n",
    "    # Create global model metrics table\n",
    "    client_global_table = pd.DataFrame({\n",
    "        'Class': list(client_global_metrics.names.values()),\n",
    "        'mAP@0.5:0.95': client_global_metrics.box.maps.tolist()\n",
    "    })\n",
    "    \n",
    "    # Combine local and global model metrics\n",
    "    combined_table = pd.merge(client_table, client_global_table, on='Class', how='inner')\n",
    "    combined_table.columns = ['Class', 'mAP@0.5:0.95_local', 'mAP@0.5:0.95_global']\n",
    "\n",
    "    del client_model\n",
    "    del client_global_model\n",
    "    \n",
    "    return combined_table\n",
    "\n",
    "print('##################')\n",
    "print('# CLIENT RESULTS #')\n",
    "print('##################')\n",
    "print()\n",
    "client_0_metrics_table = get_client_metrics(0, DATASET_NAME, HOME)\n",
    "client_1_metrics_table = get_client_metrics(1, DATASET_NAME, HOME)\n",
    "combined_table = pd.merge(client_0_metrics_table, client_1_metrics_table, on='Class', how='inner')\n",
    "combined_table.columns = ['Class', 'mAP@0.5:0.95_local_0', 'mAP@0.5:0.95_global_0', 'mAP@0.5:0.95_local_1', 'mAP@0.5:0.95_global_1']\n",
    "print()\n",
    "print()\n",
    "print('##############################')\n",
    "print('# FINAL CONSOLIDATED METRICS #')\n",
    "print('##############################')\n",
    "print(combined_table.to_string(index=False))\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################\n",
      "# SERVER RESULTS #\n",
      "##################\n",
      "\n",
      "WARNING âš ï¸ validating an untrained model YAML will result in 0 mAP.\n",
      "Ultralytics 8.3.48 ðŸš€ Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n",
      "YOLO11n_baseline summary (fused): 238 layers, 2,582,542 parameters, 12,870 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/partitions/client_0/valid/labels.cache... 6 images, 6 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         12         12    0.00193       0.35     0.0832     0.0347\n",
      "                     0          6         10    0.00386        0.7      0.166     0.0695\n",
      "                     1          1          2          0          0          0          0\n",
      "Speed: 0.5ms preprocess, 41.7ms inference, 0.0ms loss, 9.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val14\u001b[0m\n",
      "WARNING âš ï¸ validating an untrained model YAML will result in 0 mAP.\n",
      "Ultralytics 8.3.48 ðŸš€ Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/partitions/client_1/valid/labels.cache... 7 images, 6 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         13         13    0.00176      0.318     0.0821      0.065\n",
      "                     0          7         11    0.00351      0.636      0.164       0.13\n",
      "                     1          1          2          0          0          0          0\n",
      "Speed: 0.9ms preprocess, 43.8ms inference, 0.0ms loss, 6.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val15\u001b[0m\n",
      "WARNING âš ï¸ validating an untrained model YAML will result in 0 mAP.\n",
      "Ultralytics 8.3.48 ðŸš€ Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/valid/labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25         48    0.00368      0.359     0.0693     0.0429\n",
      "                     0         25         39    0.00736      0.718      0.139     0.0858\n",
      "                     1          3          9          0          0          0          0\n",
      "Speed: 0.9ms preprocess, 44.4ms inference, 0.0ms loss, 7.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val16\u001b[0m\n",
      "  Class  mAP@0.5:0.95_client_0  mAP@0.5:0.95_client_1  mAP@0.5:0.95_global\n",
      "0     0               0.069466               0.129926             0.085789\n",
      "1     1               0.000000               0.000000             0.000000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#####################\n",
    "# SERVER EVALUATION #\n",
    "#####################\n",
    "print('##################')\n",
    "print('# SERVER RESULTS #')\n",
    "print('##################')\n",
    "print()\n",
    "\n",
    "server_model = YOLO(f\"{HOME}/yolo11n_{DATASET_NAME}.yaml\")\n",
    "server_model_weights_path = f\"{HOME}/weights/model_round_{NUM_ROUNDS}_{DATASET_NAME}.pt\"\n",
    "server_model.model.load_state_dict(torch.load(server_model_weights_path)['model'].state_dict(), strict=False)\n",
    "\n",
    "server_model_client0_metrics = server_model.val(data=f'{HOME}/datasets/{DATASET_NAME}/partitions/client_0/data.yaml', verbose=True)\n",
    "server_model_client1_metrics = server_model.val(data=f'{HOME}/datasets/{DATASET_NAME}/partitions/client_1/data.yaml', verbose=True)\n",
    "server_model_global_metrics = server_model.val(data=f'{HOME}/datasets/{DATASET_NAME}/data.yaml', verbose=True)\n",
    "\n",
    "server_model_client0_table = pd.DataFrame({\n",
    "    'Class': list(server_model_client0_metrics.names.values()),\n",
    "    'mAP@0.5:0.95': server_model_client0_metrics.box.maps.tolist()\n",
    "})\n",
    "\n",
    "server_model_client1_table = pd.DataFrame({\n",
    "    'Class': list(server_model_client1_metrics.names.values()),\n",
    "    'mAP@0.5:0.95': server_model_client1_metrics.box.maps.tolist()\n",
    "})\n",
    "\n",
    "server_model_global_table = pd.DataFrame({\n",
    "    'Class': list(server_model_global_metrics.names.values()),\n",
    "    'mAP@0.5:0.95': server_model_global_metrics.box.maps.tolist()\n",
    "})\n",
    "\n",
    "# First, merge client0 and client1 tables\n",
    "server_model_combined_table = pd.merge(server_model_client0_table, server_model_client1_table, on='Class', how='inner')\n",
    "\n",
    "# Then, merge the result with the global table\n",
    "server_model_combined_table = pd.merge(server_model_combined_table, server_model_global_table, on='Class', how='inner')\n",
    "\n",
    "# Rename the columns\n",
    "server_model_combined_table.columns = ['Class', 'mAP@0.5:0.95_client_0', 'mAP@0.5:0.95_client_1', 'mAP@0.5:0.95_global']\n",
    "\n",
    "print(server_model_combined_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedlytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
